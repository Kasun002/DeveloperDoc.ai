# DeveloperDoc.ai - Quick Start Guide

> AI-powered code generation with framework documentation search

---

## ğŸ‰ NEW: Migration to Local Embeddings Complete!

**No more OpenAI quota errors!** The system now uses:
- âœ… **Local embeddings** (sentence-transformers) - FREE, unlimited, no API key
- âœ… **Gemini** for LLM operations - Better performance, lower cost
- âœ… **Automated migration** - Just run `./start_all.sh --clean`

**Quick Start**: `./start_all.sh --clean`

ğŸ“š **Migration Docs**: See `README_MIGRATION.md` for complete details

---

## Overview

DeveloperDoc.ai is an intelligent code generation system that combines multi-agent AI architecture with semantic documentation search. It helps developers generate framework-compliant code by automatically searching relevant documentation and applying best practices.

**Key Capabilities**:
- Framework-aware code generation (NestJS, React, FastAPI, Django, Express, Vue, Angular, Spring Boot, .NET Core)
- Semantic documentation search with vector similarity
- Multi-agent orchestration with supervisor routing
- Two-tier caching for optimal performance
- Support for OpenAI and Google Gemini AI

---

## Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Login    â”‚  â”‚  Register  â”‚  â”‚    Chat    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend (FastAPI)                      â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚           Semantic Cache (Redis)               â”‚     â”‚
â”‚  â”‚         Check for similar queries              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â”‚                              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         LangGraph Workflow Engine              â”‚     â”‚
â”‚  â”‚                                                â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚     â”‚
â”‚  â”‚  â”‚      Supervisor Agent (GPT-3.5)      â”‚      â”‚     â”‚
â”‚  â”‚  â”‚   Analyzes prompt & routes request   â”‚      â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚     â”‚
â”‚  â”‚                    â”‚                           â”‚     â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚     â”‚
â”‚  â”‚         â–¼                     â–¼                â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚     â”‚
â”‚  â”‚  â”‚   Search    â”‚      â”‚  Code Gen   â”‚          â”‚     â”‚
â”‚  â”‚  â”‚   Agent     â”‚      â”‚   Agent     â”‚          â”‚     â”‚
â”‚  â”‚  â”‚   (MCP)     â”‚      â”‚ (GPT-3.5)   â”‚          â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â”‚                              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         Vector Database (pgvector)             â”‚     â”‚
â”‚  â”‚    Framework documentation embeddings          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

#### 1. Multi-Agent System

**Supervisor Agent**:
- Analyzes incoming prompts
- Determines routing strategy (SEARCH_ONLY, CODE_ONLY, SEARCH_THEN_CODE)
- Orchestrates workflow between agents

**Documentation Search Agent**:
- Performs semantic search using pgvector
- Applies cross-encoder re-ranking for relevance
- Self-corrects on low confidence results
- Caches results for 5 minutes

**Code Generation Agent**:
- Generates framework-compliant code
- Uses documentation context from search
- Validates syntax automatically
- Retries on errors (max 2 attempts)

#### 2. Workflow Process

```
User Query â†’ Semantic Cache Check
                    â”‚
                    â”œâ”€ Cache Hit â†’ Return Cached Response
                    â”‚
                    â””â”€ Cache Miss â†’ Supervisor Agent
                                        â”‚
                                        â”œâ”€ Route: SEARCH_ONLY
                                        â”‚     â””â”€â†’ Search Docs â†’ Return Results
                                        â”‚
                                        â”œâ”€ Route: CODE_ONLY
                                        â”‚     â””â”€â†’ Generate Code â†’ Validate â†’ Return
                                        â”‚
                                        â””â”€ Route: SEARCH_THEN_CODE
                                              â””â”€â†’ Search Docs â†’ Generate Code â†’ Validate
                                                      â”‚
                                                      â”œâ”€ Valid â†’ Cache & Return
                                                      â”‚
                                                      â””â”€ Invalid â†’ Retry or Search Again
```

#### 3. Caching Strategy

**Semantic Cache** (Redis + pgvector):
- Stores responses with embeddings
- Similarity threshold: 0.95
- TTL: 1 hour
- Reduces LLM API calls by ~40%

**Tool Cache** (Redis):
- Caches MCP tool results
- TTL: 5 minutes
- Reduces vector search operations

---

## Backend Architecture

### Technology Stack

- **Framework**: FastAPI (Python 3.10+)
- **AI/ML**: LangGraph, LangChain, OpenAI API, Google Gemini API
- **Databases**: PostgreSQL (main + vector with pgvector), Redis
- **Observability**: OpenTelemetry, structlog

### Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/                    # AI Agents
â”‚   â”‚   â”œâ”€â”€ supervisor_agent.py   # Routes requests
â”‚   â”‚   â”œâ”€â”€ documentation_search_agent.py  # Searches docs
â”‚   â”‚   â”œâ”€â”€ code_gen_agent.py     # Generates code
â”‚   â”‚   â””â”€â”€ syntax_validator.py   # Validates syntax
â”‚   â”‚
â”‚   â”œâ”€â”€ api/v1/endpoints/          # API Endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py               # Authentication
â”‚   â”‚   â”œâ”€â”€ agent.py              # AI Agent queries
â”‚   â”‚   â””â”€â”€ dashboard.py          # User dashboard
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                      # Core functionality
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”‚   â”œâ”€â”€ database.py           # Main DB connection
â”‚   â”‚   â”œâ”€â”€ vector_database.py    # Vector DB manager
â”‚   â”‚   â”œâ”€â”€ security.py           # JWT & auth
â”‚   â”‚   â””â”€â”€ telemetry.py          # OpenTelemetry
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                  # Business logic
â”‚   â”‚   â”œâ”€â”€ embedding_service.py  # Generate embeddings
â”‚   â”‚   â”œâ”€â”€ semantic_cache.py     # Semantic caching
â”‚   â”‚   â”œâ”€â”€ tool_cache.py         # Tool result caching
â”‚   â”‚   â”œâ”€â”€ vector_search_service.py  # Vector search
â”‚   â”‚   â”œâ”€â”€ reranking_service.py  # Re-rank results
â”‚   â”‚   â”œâ”€â”€ framework_detector.py # Auto-detect framework
â”‚   â”‚   â””â”€â”€ gemini_client.py      # Gemini AI client
â”‚   â”‚
â”‚   â”œâ”€â”€ workflows/                 # LangGraph workflows
â”‚   â”‚   â””â”€â”€ agent_workflow.py     # Orchestration logic
â”‚   â”‚
â”‚   â””â”€â”€ main.py                    # Application entry
â”‚
â”œâ”€â”€ alembic/                       # Database migrations
â”œâ”€â”€ tests/                         # Test suite
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ .env                          # Environment variables
```

### Key Features

**Multi-Agent Orchestration**:
- Supervisor routes to specialized agents
- Iterative refinement with cycles
- Max 3 workflow iterations

**Vector Search**:
- pgvector with HNSW indexing (O(log N) performance)
- 1536-dimensional embeddings (text-embedding-3-small)
- Cross-encoder re-ranking for accuracy

**LLM Provider Flexibility**:
- OpenAI (gpt-3.5-turbo) - Default
- Google Gemini (gemini-1.5-flash) - Alternative
- Switch with single environment variable

**Observability**:
- OpenTelemetry distributed tracing
- Structured JSON logging
- Trace IDs for request tracking

---

## Frontend Architecture

### Technology Stack

- **Framework**: React 19.2.0 with TypeScript
- **Build Tool**: Vite 7.2.4
- **Styling**: Tailwind CSS 4.1.18
- **Routing**: React Router DOM 7.13.0
- **Forms**: React Hook Form 7.71.1
- **Notifications**: React Hot Toast 2.6.0

### Project Structure

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/               # UI Components
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx    # Main chat UI
â”‚   â”‚   â”œâ”€â”€ LoginForm.tsx        # Login form
â”‚   â”‚   â”œâ”€â”€ RegisterForm.tsx     # Registration form
â”‚   â”‚   â””â”€â”€ MarkdownRenderer.tsx # Display AI responses
â”‚   â”‚
â”‚   â”œâ”€â”€ pages/                   # Page components
â”‚   â”‚   â”œâ”€â”€ ChatPage.tsx         # Chat page
â”‚   â”‚   â”œâ”€â”€ LoginPage.tsx        # Login page
â”‚   â”‚   â””â”€â”€ RegisterPage.tsx     # Register page
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                  # Routing
â”‚   â”‚   â”œâ”€â”€ AppRouter.tsx        # Main router
â”‚   â”‚   â””â”€â”€ ProtectedRoute.tsx   # Auth guard
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # API services
â”‚   â”‚   â”œâ”€â”€ authService.ts       # Auth API calls
â”‚   â”‚   â””â”€â”€ agentService.ts      # Agent API calls
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Utilities
â”‚   â”‚   â”œâ”€â”€ toast.ts             # Toast notifications
â”‚   â”‚   â””â”€â”€ cookieUtils.ts       # Cookie management
â”‚   â”‚
â”‚   â”œâ”€â”€ App.jsx                  # Root component
â”‚   â””â”€â”€ main.jsx                 # Entry point
â”‚
â”œâ”€â”€ public/                      # Static assets
â”œâ”€â”€ package.json                 # Dependencies
â””â”€â”€ vite.config.js              # Vite config
```

### Key Features

**Authentication**:
- JWT-based authentication
- Secure cookie storage
- Protected routes with guards
- Auto-redirect on session expiration

**Chat Interface**:
- ChatGPT-like UI design
- Real-time query submission
- Markdown rendering for responses
- Loading states with spinners

**Toast Notifications**:
- Success (green) - Successful operations
- Error (red) - Failed operations
- Loading (blue) - In-progress operations
- Auto-dismiss with smooth animations

**Responsive Design**:
- Mobile-first approach
- Works on all screen sizes
- Touch-friendly interface

---

## Local Setup

### Prerequisites

- **Docker Desktop** (for databases)
- **Python 3.10+** and pip
- **Node.js 18+** and npm
- **OpenAI API Key** (or Gemini API Key)

### 1. Clone Repository

```bash
git clone <repository-url>
cd developerdoc-ai
```

### 2. Start Infrastructure Services

```bash
# Start PostgreSQL (main + vector) and Redis
docker-compose up -d postgres postgres-vector redis
```

Verify services are running:
```bash
docker-compose ps
```

You should see:
- `postgres` - Main PostgreSQL (port 5432)
- `postgres-vector` - Vector PostgreSQL (port 5433)
- `redis` - Redis cache (port 6379)

### 3. Setup Backend

#### Install Dependencies

```bash
cd backend
pip install -r requirements.txt
```

#### Configure Environment

```bash
cp .env.example .env
```

Edit `.env` and add your API key:
```env
# Required
OPENAI_API_KEY=sk-your-openai-api-key-here

# Or use Gemini instead
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-gemini-api-key-here

# Database URLs (already configured for local Docker)
DATABASE_URL=postgresql://admin:admin123@localhost:5432/ai_admin
VECTOR_DATABASE_URL=postgresql://vector_admin:vector123@localhost:5433/ai_agent_vectors
REDIS_URL=redis://localhost:6379/0

# JWT Secret (generate with: openssl rand -hex 32)
JWT_SECRET_KEY=your-256-bit-secret-key-change-in-production
```

#### Run Database Migrations

```bash
alembic upgrade head
```

#### Start Backend Server

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at: `http://localhost:8000`

API Documentation: `http://localhost:8000/docs`

### 4. Setup Frontend

#### Install Dependencies

```bash
cd frontend
npm install
```

#### Start Development Server

```bash
npm run dev
```

Frontend will be available at: `http://localhost:5173`

### 5. Verify Setup

#### Check Backend Health

```bash
curl http://localhost:8000/health
```

Expected response:
```json
{
  "status": "healthy",
  "database": "connected"
}
```

#### Check Frontend

Open browser: `http://localhost:5173`

You should see the login page.

### 6. Test the Application

1. **Register a new user**:
   - Go to `http://localhost:5173/register`
   - Enter email and password
   - Click "Register"
   - You should see a success toast and be redirected to chat

2. **Submit a query**:
   - Enter: "Create a NestJS controller for user authentication"
   - Click "Send"
   - You should see:
     - Blue loading toast
     - Green success toast when complete
     - AI-generated code in markdown format

---

## Quick Commands Reference

### Backend

```bash
# Start backend
cd backend
uvicorn app.main:app --reload

# Run migrations
alembic upgrade head

# Create new migration
alembic revision --autogenerate -m "description"

# Run tests
pytest -v

# Check health
curl http://localhost:8000/health
```

### Frontend

```bash
# Start frontend
cd frontend
npm run dev

# Build for production
npm run build

# Run linter
npm run lint

# Preview production build
npm run preview
```

### Docker Services

```bash
# Start all services
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs -f postgres
docker-compose logs -f redis

# Restart a service
docker-compose restart postgres
```

### Database

```bash
# Connect to main database
docker exec -it postgres psql -U admin -d ai_admin

# Connect to vector database
docker exec -it postgres-vector psql -U vector_admin -d ai_agent_vectors

# Connect to Redis
docker exec -it redis redis-cli
```

---

## Environment Variables

### Backend (.env)

```env
# Application
APP_ENV=development
APP_NAME=DeveloperDocAI

# Databases
DATABASE_URL=postgresql://admin:admin123@localhost:5432/ai_admin
VECTOR_DATABASE_URL=postgresql://vector_admin:vector123@localhost:5433/ai_agent_vectors
REDIS_URL=redis://localhost:6379/0

# LLM Provider (choose one)
LLM_PROVIDER=openai                    # or "gemini"
OPENAI_API_KEY=sk-your-key-here       # if using OpenAI
GEMINI_API_KEY=your-key-here          # if using Gemini

# JWT Configuration
JWT_SECRET_KEY=your-256-bit-secret-key
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI Agent Configuration
SEMANTIC_CACHE_THRESHOLD=0.95
SEMANTIC_CACHE_TTL=3600
TOOL_CACHE_TTL=300
MAX_WORKFLOW_ITERATIONS=3

# Vector Search
VECTOR_SEARCH_TOP_K=10
VECTOR_SEARCH_MIN_SCORE=0.7

# Observability
OTEL_ENABLED=true
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### Frontend

No environment variables needed for local development. Backend URL is hardcoded to `http://localhost:8000`.

For production, update API URLs in:
- `frontend/src/services/authService.ts`
- `frontend/src/services/agentService.ts`

---

## Troubleshooting

### Backend Issues

**Can't connect to database**:
```bash
# Check if containers are running
docker-compose ps

# Restart PostgreSQL
docker-compose restart postgres postgres-vector
```

**OpenAI API errors**:
- Verify API key is correct in `.env`
- Check API key has sufficient credits
- Try switching to Gemini: `LLM_PROVIDER=gemini`

**Migration errors**:
```bash
# Check current migration status
alembic current

# Rollback and reapply
alembic downgrade -1
alembic upgrade head
```

### Frontend Issues

**Can't connect to backend**:
- Verify backend is running on `http://localhost:8000`
- Check backend health: `curl http://localhost:8000/health`
- Check browser console for CORS errors

**Toast notifications not showing**:
```bash
# Reinstall dependencies
rm -rf node_modules package-lock.json
npm install
```

**Build errors**:
```bash
# Clear cache and rebuild
rm -rf node_modules dist
npm install
npm run build
```

---

## Switching LLM Providers

### From OpenAI to Gemini

1. Get Gemini API key: https://makersuite.google.com/app/apikey

2. Update `backend/.env`:
```env
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-gemini-api-key
```

3. Restart backend:
```bash
# Stop with Ctrl+C, then restart
uvicorn app.main:app --reload
```

### From Gemini to OpenAI

Update `backend/.env`:
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-key
```

Restart backend.

---

## Project Status

**Version**: 1.2.0  
**Status**: Production Ready âœ…

**Backend**: Operational
- Multi-agent system
- Vector search
- Semantic caching
- OpenAI & Gemini support

**Frontend**: Operational
- React application
- Authentication
- Chat interface
- Toast notifications

---

## Documentation

**Detailed Documentation**:
- [Full README](README.md) - Complete documentation
- [Backend README](backend/README.md) - Backend details
- [Frontend Toast Docs](frontend/TOAST_SETUP_COMPLETE.md) - Toast notifications

---

## Support

For issues or questions:
1. Check the [Full README](README.md)
2. Review troubleshooting section above
3. Check Docker logs: `docker-compose logs -f`
4. Verify environment variables in `.env`

---

**Built with â¤ï¸ by the DeveloperDoc.ai Team**
