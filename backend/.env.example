# Application settings
APP_ENV=development
APP_NAME=DeveloperDocAI
APP_HOST=0.0.0.0
APP_PORT=8000

# PostgreSQL Database configuration
# Connection string format: postgresql://username:password@host:port/database
# Main database for authentication and basic operations
# For local Docker PostgreSQL: postgresql://admin:admin123@localhost:5432/ai_admin
# For production: Use environment-specific credentials
DATABASE_URL=postgresql://admin:admin123@localhost:5432/ai_admin

# Vector database for AI Agent framework documentation and embeddings
# For local Docker PostgreSQL with pgvector: postgresql://vector_admin:vector123@localhost:5433/ai_agent_vectors
# For production: Use managed vector database service
VECTOR_DATABASE_URL=postgresql://vector_admin:vector123@localhost:5433/ai_agent_vectors

# JWT configuration
# IMPORTANT: Change this secret key in production!
# Generate a secure key with: openssl rand -hex 32
JWT_SECRET_KEY=your-256-bit-secret-key-change-this-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# Password reset configuration
PASSWORD_RESET_TOKEN_EXPIRE_HOURS=1

# Password hashing configuration
BCRYPT_ROUNDS=12

# Other API keys
SECRET_KEY=your-secret-key
OPENAI_API_KEY=your-openai-key

# Redis Configuration (for caching)
REDIS_URL=redis://localhost:6379/0
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# AI Agent Configuration
# Semantic cache similarity threshold (0.0-1.0)
SEMANTIC_CACHE_THRESHOLD=0.95
SEMANTIC_CACHE_TTL=3600  # 1 hour in seconds

# Tool cache TTL (5-10 minutes)
TOOL_CACHE_TTL=300  # 5 minutes in seconds

# LangGraph workflow configuration
MAX_WORKFLOW_ITERATIONS=3

# Vector search configuration
VECTOR_SEARCH_TOP_K=10
VECTOR_SEARCH_MIN_SCORE=0.7

# Cross-encoder model for re-ranking
CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Embedding model
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# MCP Tool Configuration
MCP_TOOL_RETRY_ATTEMPTS=3
MCP_TOOL_RETRY_BACKOFF_MULTIPLIER=1
MCP_TOOL_RETRY_MIN_WAIT=1
MCP_TOOL_RETRY_MAX_WAIT=10

# Observability
OTEL_ENABLED=true
OTEL_SERVICE_NAME=ai-agent-system
OTEL_EXPORTER_TYPE=console  # console, jaeger, or otlp

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json  # json or text
